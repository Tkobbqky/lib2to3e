大数据技术入门 PDF下载 杨正洪 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#730244283
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#730244283
<p>书名:大数据技术入门</p><p>作者:杨正洪</p><p>页数:292</p><p>定价:¥59.0</p><p>出版社:清华大学出版社</p><p>出版日期:2016-08-01</p><p>ISBN:9787302442837</p><p><h2>本书特色</h2></p>[<p>
从2015年开始，国内大数据市场继续保持高速的发展态势，作者在与地方政府、证券金融公司的项目合作中发现，他们对大数据技术很感兴趣，并希望从大数据技术、大数据采集、管理、分析以及可视化等方面得到指导和应用帮助。因此编写了这本大数据技术的快速入门书。
本书共12章，以hadoop和spark框架为线索，比较全面地介绍了hadoop技术、spark技术、大数据存储、大数据访问、大数据采集、大数据管理、大数据分析等内容。*后还给出两个案例：环保大数据和公安大数据，供读者参考。
本书适合大数据技术初学者，政府、金融机构的大数据应用决策和技术人员，it经理，cto，cio等快速学习大数据技术。本书也可以作为高等院校和培训学校相关专业的培训教材。
                                        </p>]<p><h2>内容简介</h2></p>[<p>本书作者杨正洪是国内知名大数据专家，是华中科技大学和中国地质大学客座教授,拥有国家专利,是湖北省2013年海外引进的科技人才，受武汉市政府邀请，成立武汉市云升科技发展有限公司，在浙江和上海分别有全资子公司，在美国硅谷设有研发中心。作者在与地方政府、证券金融公司的项目合作中发现，他们对大数据技术很感兴趣，并希望从大数据技术、大数据采集、管理、分析以及可视化等方面得到指导和应用帮助。因此编写了这本大数据技术的快速入门书。本书以hadoop和spark框架为线索，比较全面地介绍了hadoop技术、spark技术、大数据存储、大数据访问、大数据采集、大数据管理、大数据分析等内容。*后还给出两个案例：环保大数据和公安大数据，供读者参考。
 </p>]<p><h2>作者简介</h2></p>[<p>本书作者杨正洪是国内知名大数据专家，毕业于美国State University of New York at Stony Brook，在IBM公司从事大数据相关研发工作12年多。从2003~2013年，杨正洪在美国加州的IBM硅谷实验室（IBM Silicon Valley Lab）负责IBM大数据平台的设计、研发和实施，主持了保险行业、金融行业、政府行业的大数据系统的架构设计和实施。杨正洪是华中科技大学和中国地质大学客座教授，拥有国家专利，是湖北省2013年海外引进人才。受武汉市政府邀请，杨正洪于2012年12月发起成立武汉市云升科技发展有限公司，并获得东湖高新技术开发区办公场所和资金支持。目前公司在浙江和上海分别有全资子公司，在美国硅谷设有研发中心。公司的核心产品是大数据管理平台EasyDoop，并以EasyDoop为基础研发了公安大数据产品和环保大数据产品。这些产品在公安和环保行业得到成功实施，三次被中央电视台新闻联播节目播报，省部长级政府领导亲自考察，并给予了很高的评价。杨正洪参与了多项大数据相关标准的制定工作，曾受邀参与了公安部主导的“信息安全技术-大数据平台安全管理产品安全技术要求”的国家标准制定。</p>]<p><h2>目录</h2></p>
    目  录第1章  大数据时代 11.1  什么是大数据 11.2  大数据的四大特征 21.3  大数据的商用化 31.4  大数据分析 51.5  大数据与云计算的关系 51.6  大数据的国家战略 61.6.1  政府大数据的价值 71.6.2  政府大数据的应用场景81.7  企业如何迎接大数据 81.7.1  评估大数据方案的维度91.7.2  业务价值维度 101.7.3  数据维度 111.7.4  现有it环境和成本维度 121.7.5  数据治理维度 131.8  大数据产业链分析 141.8.1  技术分析 141.8.2  角色分析 151.8.3  大数据运营 171.9  大数据交易 181.10  大数据之我见 19第2章  大数据软件框架 202.1  hadoop框架 202.1.1  hdfs（分布式文件系统） 212.1.2  mapreduce（分布式计算框架） 222.1.3  yarn（集群资源管理器） 252.1.4  zookeeper（分布式协作服务） 282.1.5  ambari（管理工具） 292.2  spark（内存计算框架） 292.2.1  scala 312.2.2  spark sql 322.2.3  spark streaming 332.3  实时流处理框架 342.4  框架的选择 35第3章  安装与配置大数据软件 363.1  hadoop发行版 363.1.1  cloudera 363.1.2  hortonworks 373.1.3  mapr 383.2  安装hadoop前的准备工作 393.2.1  linux主机配置403.2.2  配置java环境 413.2.3  安装ntp和python 423.2.4  安装和配置openssl433.2.5  启动和停止特定服务443.2.6  配置ssh无密码访问 443.3  安装ambari 和 hdp 453.3.1  配置安装包文件 453.3.2  安装 ambari463.3.3  安装和配置hdp473.4  初识hadoop 493.4.1  启动和停止服务 503.4.2  使用hdfs 513.5  hadoop的特性 52第4章  大数据存储：文件系统 534.1  hdfs shell命令534.2  hdfs配置文件 554.3  hdfs api编程574.3.1  读取hdfs文件内容 574.3.2  写hdfs文件内容 604.4  hdfs api总结624.4.1  configuration类 624.4.2  filesystem抽象类 624.4.3  path类 634.4.4  fsdatainputstream类 634.4.5  fsdataoutputstream类 634.4.6  ioutils类634.4.7  filestatus类 644.4.8  fsshell类644.4.9  checksumfilesystem抽象类 644.4.10  其他hdfsapi实例 644.4.11  综合实例 674.5  hdfs文件格式 694.5.1  sequencefile 704.5.2  textfile（文本格式） 704.5.3  rcfile 704.5.4  avro 72第5章  大数据存储：数据库 735.1  nosql 735.2  hbase管理 745.2.1  hbase表结构755.2.2  hbase系统架构785.2.3  启动并操作hbase数据库 805.2.4  hbase shell工具 825.3  hbase编程 865.3.1  增删改查api 865.3.2  过滤器 905.3.3  计数器 935.3.4  原子操作 945.3.5  管理api 945.4  其他nosql数据库 95第6章  大数据访问：sql引擎层 976.1  phoenix 976.1.1  安装和配置phoenix986.1.2  在eclipse上开发phoenix程序 1046.1.3  phoenix sql工具 1086.1.4  phoenix sql 语法 1096.2  hive 1116.2.1  hive架构 1116.2.2  安装hive 1126.2.3  hive和mysql的配置 1146.2.4  hive cli 1156.2.5  hive数据类型1156.2.6  hiveql ddl 1196.2.7  hiveql dml 1216.2.8  hive编程 1236.2.9  hbase集成1256.2.10  xml和json数据 1276.2.11  使用tez 1286.3  pig 1306.3.1  pig语法 1316.3.2  pig和hive的使用场景比较 1346.4  elasticsearch（全文搜索引擎） 1366.4.1  全文索引的基础知识1366.4.2  安装和配置es1386.4.3  es api 140第7章  大数据采集和导入 1437.1  flume 1457.1.1  flume架构1457.1.2  flume事件1467.1.3  flume源 1477.1.4  flume拦截器（interceptor） 1487.1.5  flume通道选择器（channel selector） 1497.1.6  flume通道1507.1.7  flume接收器1517.1.8  负载均衡和单点失败1537.1.9  flume监控管理1537.1.10  flume实例1547.2  kafka 1557.2.1  kafka架构1567.2.2  kafka与jms的异同 1587.2.3  kafka性能考虑1587.2.4  消息传送机制 1597.2.5  kafka和flume的比较 1597.3  sqoop 1607.3.1  从数据库导入hdfs1607.3.2  增量导入 1637.3.3  将数据从oracle导入hive 1637.3.4  将数据从oracle导入hbase 1647.3.5  导入所有表 1657.3.6  从hdfs导出数据 1657.3.7  数据验证 1657.3.8  其他sqoop功能 1657.4  storm 1677.4.1  storm基本概念1687.4.2  spout 1697.4.3  bolt 1717.4.4  拓扑 1737.4.5   storm总结1757.5  splunk 175第8章  大数据管理平台 1778.1  大数据建设总体架构1778.2  大数据管理平台的必要性1788.3  大数据管理平台的功能1798.3.1  推进数据资源全面整合共享 1798.3.2  增强数据管理水平1808.3.3  支撑创新大数据分析1808.4  数据管理平台（dmp） 1808.5  easydoop案例分析1828.5.1  大数据建模平台1838.5.2  大数据交换和共享平台1848.5.3  大数据云平台 1858.5.4  大数据服务平台1868.5.5  easydoop平台技术原理分析 188第9章  spark技术 1929.1  spark框架 1929.1.1  安装spark1939.1.2  配置spark1949.2  spark shell 1959.3  spark编程 1989.3.1  编写sparkapi程序 1989.3.2  使用sbt编译并打成jar包 1999.3.3  运行程序 2009.4  rdd 2009.4.1  rdd算子和rdd依赖关系 2019.4.2  rdd转换操作2039.4.3  rdd行动（action）操作 2049.4.4  rdd控制操作2059.4.5  rdd实例 2059.5  spark sql 2089.5.1  dataframe 2099.5.2  rdd转化为dataframe2139.5.3  jdbc数据源2159.5.4  hive数据源2169.6  spark streaming 2179.6.1  dstream编程模型 2189.6.2  dstream操作2219.6.3  性能考虑 2239.6.4  容错能力 2249.7  graphx图计算框架2249.7.1  属性图 2269.7.2  图操作符 2289.7.3  属性操作 2319.7.4  结构操作 2319.7.5  关联（join）操作 2339.7.6  聚合操作 2349.7.7  计算度信息 2359.7.8  缓存操作 2369.7.9  图算法 236第10章  大数据分析 23810.1  数据科学 23910.1.1  探索性数据分析24010.1.2  描述统计 24110.1.3  数据可视化 24110.2  预测分析 24410.2.1  预测分析实例24410.2.2  回归（regression）分析预测法 24610.3  机器学习 24710.3.1  机器学习的市场动态24810.3.2  机器学习分类24910.3.3  机器学习算法25110.4  spark mlib 25210.4.1  mlib架构25310.4.2  mlib算法库25310.4.3  决策树 25710.5  深入了解算法 26110.5.1  分类算法 26210.5.2  预测算法 26310.5.3  聚类分析 26310.5.4  关联分析 26410.5.5  异常值分析算法26610.5.6  协同过滤（推荐引擎）算法 26710.6  mahout简介267第11章  案例分析：环保大数据 26811.1  环保大数据管理平台26811.2  环保大数据应用平台26911.2.1  环境自动监测监控服务 27011.2.2  综合查询服务27211.2.3  统计分析服务27211.2.4  gis服务 27411.2.5  视频服务 27411.2.6  预警服务 27511.2.7  应急服务 27611.2.8  电子政务服务27711.2.9  智能化运营管理系统27911.2.10  环保移动应用系统27911.2.11  空气质量发布系统28011.3  环保大数据分析系统280第12章  案例分析：公安大数据 28112.1  总体架构设计 28112.2  建设内容 28212.3  建设步骤 284附录 1  数据量的单位级别 285附录 2  linux shell常见命令 286附录 3  ganglia（分布式监控系统） 289附录 4  auth-ssh脚本 290附录 5  作者简介 292
