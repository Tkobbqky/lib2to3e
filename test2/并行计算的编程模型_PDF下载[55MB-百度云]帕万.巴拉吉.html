并行计算的编程模型 PDF下载 帕万.巴拉吉 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711157334
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711157334
<p>书名:并行计算的编程模型</p><p>作者:帕万.巴拉吉</p><p>页数:289</p><p>定价:¥79.0</p><p>出版社:机械工业出版社</p><p>出版日期:2017-07-01</p><p>ISBN:9787111573340</p><p><h2>本书特色</h2></p>[<p>
本书以使用说明的形式对当今主流的并行编程模型进行了详细描述，内容包括分布式内存架构上常见的MPI（消息传递接口）编程模型；单边通信模型，范围从低层的运行时库（GASNet、OpenSHMEM）到高层的编程模型（UPC、GA、Chapel）；面向任务的编程模型，包括Charm  、ADLB、Scioto、Swift、CnC，由运行时系统来管理计算和数据移动；面向节点内并行（多核架构以及附带加速器）的并行编程模型，包括OpenMP、CilkPlus、TBB、CUDA以及OpenCL。每章配备大量应用和程序实例，可以使读者很好地理解各种编程模型所提供的功能及特点。本书可作为高等院校并行编程课程的研究生教材，也可作为具有一定并行编程经验的软件开发人员、科研人员以及任何与数据集及大规模计算打交道的科学家的参考资料。
                                        </p>]<p><h2>作者简介</h2></p>[<p>中国科学院外籍青年科学家、美国阿贡国家实验室(Argonne National Laboratory)计算机科学家。美国西北大学西北-阿贡研究所和工程学院研究员，芝加哥大学计算所研究员。</p>]<p><h2>目录</h2></p>
    出版者的话译者序前言第1章　消息传递接口 11.1　引言 11.2　MPI基础 11.3　点对点通信 21.4　数据类型 31.5　非阻塞式通信 41.6　聚合通信 51.7　单边通信 71.8　并行I/O 91.9　其他特性 111.10　MPI开发心得 121.11　总结 13第2章　全局地址空间网络 142.1　研究背景与动机 142.2　GASNet概述 142.2.1　相关术语 152.2.2　线程 152.2.3　API组织 162.3　核心API 162.3.1　开始和结束 162.3.2　段信息 182.3.3　屏障 182.3.4　锁与中断 192.3.5　活动消息 202.3.6　活动消息进程 222.3.7　活动消息规则与约束 222.3.8　出错代码 232.4　扩展API 232.4.1　GASNet段 232.4.2　排序与内存模型 242.4.3　阻塞与非阻塞 242.4.4　批量与单个 242.4.5　寄存器–内存与远程memset操作 242.4.6　扩展API总结 252.5　附加内容 262.5.1　GASNet工具 262.5.2　可移植平台头文件 272.6　示例 272.6.1　编译和运行示例 272.6.2　Hello World示例 282.6.3　AM Ping-Pong示例 282.6.4　AM Ring示例 302.6.5　MCS Locks示例 322.7　未来方向 35第3章　OpenSHMEM 373.1　引言 373.2　设计理念和根据 373.3　OpenSHMEM存储模型 393.4　对称堆管理 393.4.1　初始化和查询 403.4.2　分配和释放 403.4.3　关于分配和对称堆的说明 413.5　远程内存访问：put和get 413.5.1　RMA函数语义 413.5.2　RMA函数使用 423.6　排序和同步 443.6.1　全局同步屏障 443.6.2　fence和quiet：RMA操作排序 453.6.3　锁 463.6.4　wait和wait_until 463.7　集合操作 473.7.1　选择集合参与者 473.7.2　同步数组和工作数组 473.7.3　非全局同步屏障 483.7.4　广播 483.7.5　收集 493.7.6　归约 503.8　原子内存操作 513.8.1　原子加和递增 523.8.2　原子取–加和取–递增 523.8.3　原子交换和条件交换 533.9　未来方向 54第4章　统一并行C 554.1　UPC简史 554.2　UPC编程模型 564.2.1　术语 564.2.2　全局地址空间 564.2.3　执行模型 574.3　UPC概览 574.3.1　自省 574.3.2　数据布局 574.3.3　通信 594.3.4　UPC内存一致性模型 604.3.5　同步 614.3.6　集合操作 624.4　UPC程序示例 634.4.1　随机访问基准 634.4.2　雅可比5点stencil 644.4.3　排序示例 654.4.4　一维FFT 684.5　未来方向 71第5章　全局数组 725.1　引言 725.2　编程模型与设计原则 735.3　核心功能 745.4　进程组 775.5　扩展的数组结构 785.6　稀疏数组操作的支持 795.7　数组上的集合操作 805.8　动态负载均衡 805.9　实际应用 80第6章　Chapel 826.1　Chapel简史 826.1.1　全面启动 826.1.2　初始方向 836.1.3　HPCS时代 836.1.4　后HPCS时代 846.2　Chapel的主题思想 846.2.1　通用并行性表达 846.2.2　支持多线程执行模型 856.2.3　支持全局视图编程 856.2.4　支持多尺度设计 856.2.5　支持局部性控制 866.2.6　支持以数据为中心的同步 866.2.7　用户与编译器的不同角色 866.2.8　缩小主流语言和HPC语言之间的差距 876.2.9　从头开始（但争取令人熟悉） 876.2.10　远大目标 886.2.11　促使Chapel成为可移植的开源软件 886.3　Chapel特性概述 886.3.1　基本语言特性 896.3.2　任务并行 926.3.3　数据并行 966.3.4　位置特性 986.4　总结与未来方向 100第7章　Charm   1027.1　引言 1027.2　Charm的编程范例以及执行模型 1027.2.1　以过分解作为核心思想 1027.2.2　消息驱动的执行模型 1037.2.3　授权自适应运行时系统 1047.3　基本语言 1047.3.1　chare：分解的基本单元 1047.3.2　入口方法：基本的调度单元 1057.3.3　异步方法调用 1057.3.4　带索引的chare集合：chare数组 1057.3.5　只读变量 1067.3.6　Charm  对象：用户及系统角度 1077.3.7　结构化匕首符号 1087.3.8　示例：一维分解的5点stencil代码 1087.4　过分解的好处以及消息驱动执行 1107.4.1　不依赖于处理器个数 1107.4.2　异步归约 1107.4.3　自适应计算与通信重叠 1107.4.4　合成性 1117.4.5　软件工程方面的好处：逻辑实体的相互独立 1117.5　一个设计示例：分子动力学模拟 1117.6　自适应运行时特性 1127.6.1　Charm  中负载均衡功能 1127.6.2　容错 1137.6.3　缩小或扩展处理器集合 1147.6.4　异构处理器以及加速器的支持 1157.6.5　额外特性 1157.6.6　实验特性：热能与功耗管理 1157.7　底层架构概述 1157.8　基于Charm  的高层次语言家族 1167.9　通过Charm  来开发应用程序 1177.10　作为研究工具的Charm   1187.11　Charm  ：历史以及现状 1187.12　总结 118第8章　异步动态负载均衡 1198.1　引言 1198.2　manager-worker模型与负载均衡 1198.3　ADLB库定义 1218.3.1　API简介 1218.3.2　基本的ADLB API 1228.3.3　使用批处理优化内存使用 1238.3.4　获取和使用ADLB 1248.4　实现ADLB 1248.4.1　ADLBM实现 1248.4.2　其他实现 1258.5　示例 1258.5.1　一个简单的批处理调度 1258.5.2　动态任务创建：数独解法 1268.5.3　任务单元类型：旅行推销员问题 1278.5.4　GFMC 1278.5.5　Swift 1288.6　DMEM：一个处理大数据的辅助库 1288.7　总结与未来方向 129第9章　可拓展任务对象集合 1309.1　Scioto任务并行执行模型 1319.1.1　任务对象 1319.1.2　任务输入/输出模型 1329.1.3　任务执行模型 1329.2　多级并行任务集合 1339.3　Scioto   GA编程接口 1349.3.1　核心编程结构 1349.3.2　实现一个Scioto任务 1359.3.3　示例：矩阵–矩阵乘法 1359.4　Scioto运行时系统 1369.4.1　共享任务队列方法 1369.4.2　动态负载均衡方法 1379.4.3　终止检测 1379.5　总结 138第10章　Swift：极端规模的隐式并行脚本 13910.1　**个示例：并行因式分解 14010.2　一个真实的示例：晶体坐标转换 14010.3　Swift发展历史 14210.4　Swift语言和编程模型 14210.4.1　Hello World示例 14310.4.2　变量和标量数据类型 14310.4.3　数据流执行 14410.4.4　条件判断语句 14510.4.5　数据依赖控制流 14510.4.6　foreach循环和数组 14510.4.7　Swift函数 14610.4.8　外部函数 14710.4.9　文件和app函数 14810.5　Swift执行模型 14810.6　大规模并行运行时系统 15010.7　运行时架构 15110.8　性能分析 15310.9　Swift的大规模并行编译 15310.10　相关工作 15410.11　总结 155第11章　并发集合编程模型 15711.1　引言 15711.2　研究动机 15811.3　CnC领域语言 15811.3.1　概述 15811.3.2　特征 16011.3.3　示例 16111.3.4　执行语义 16211.3.5　CnC编程 16311.3.6　未来工作 16711.4　CnC调优语言 16811.4.1　描述 16811.4.2　特征 17111.4.3　示例 17111.4.4　执行模型 17311.4.5　未来工作 17511.5　当前状态 17511.6　相关工作 17511.7　总结 177第12章　OpenMP 17812.1　引言 17812.2　概述 17912.2.1　术语 17912.2.2　管理数据环境 18012.2.3　OpenMP概念简述 18112.3　OpenMP特性 18212.3.1　并行区域 18212.3.2　同步 18612.3.3　工作共享 18712.3.4　任务并行化 19112.3.5　向量化 19512.3.6　加速器支持 19612.3.7　区域取消 19912.4　性能优化建议 20012.5　关于正确性的思考 20112.6　总结与未来方向 201第13章　Cilk Plus 20213.1　引言 20213.2　向量并行化 20313.2.1　数组标注 20413.2.2　pragma SIMD 20513.2.3　支持SIMD的函数 20613.3　线程并行 20813.4　并行性能 21113.5　数据竞争 21513.6　实践技巧 21613.7　历史 21913.8　总结 220第14章　Intel TBB工具 22114.1　引言 22114.1.1　概述 22114.1.2　基本信息 22114.2　泛型并行算法 22214.2.1　简单循环的并行化 22214.2.2　在STL容器中处理数据 22314.2.3　复杂迭代空间 22414.2.4　其他算法 22614.3　流图 22614.3.1　概述 22714.3.2　节点通信协议 22714.3.3　控制依赖图 22814.3.4　数据流图 23014.3.5　流图、算法和无环图的选择 23214.4　总结 232第15章　CUDA 23315.1　CUDA简史 23315.2　CUDA编程结构 23415.3　示例：向量加法 23515.4　设备内存和数据传输 23615.5　kernel函数与线程 23815.6　线程组织 24015.7　线程和多维数据的映射 24215.8　同步与透明可扩展性 24315.9　线程块的资源分配 24415.10　CUDA流与任务并行 24415.11　总结 248第16章　OpenCL开放计算语言 24916.1　计算语言与OpenCL 24916.2　基本定义 25016.3　计算机、编程和异构 25016.4　OpenCL的诞生 25116.5　OpenCL的核心模型 25216.5.1　平台模型 25216.5.2　执行模型 25316.5.3　内存模型 25516.5.4　编程模型 25716.6　OpenCL主机程序：向量加法 25816.7　总结 266参考文献 268
