大数据Hadoop 3.X分布式处理实战 PDF下载 吴章勇，杨强编著 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711552466
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711552466
<p>书名:大数据Hadoop 3.X分布式处理实战</p><p>作者:吴章勇，杨强编著</p><p>页数:10,370页</p><p>定价:¥79.0</p><p>出版社:人民邮电出版社</p><p>出版日期:2020-04-01</p><p>ISBN:9787115524669</p><p><h2>本书特色</h2></p>[<p>
本书以实战开发为原则，以Hadoop 3.X生态系统内的主要大数据工具整合应用及项目开发为主线，通过Hadoop大数据开发中常见的11个典型模块和3个完整项目案例，详细介绍HDFS、MapReduce、HBase、Hive、Sqoop、Spark等主流大数据工具的整合使用。本书附带资源包括本书核心内容的教学视频，本书所涉及的源代码、参考资料等。 全书共14章，分为3篇，涵盖的主要内容有Hadoop及其生态组件伪分布式安装和完全分布式安装、分布式文件系统HDFS、分布式计算框架MapReduce、NoSQL数据库HBase、分布式数据仓库Hive、数据转换工具Sqoop、内存计算框架Spark、海量Web日志分析系统、电商商品推荐系统、分布式垃圾消息识别系统等。 本书内容丰富、案例典型、实用性强，适合各个层次希望学习大数据开发技术的人员阅读，尤其适合有一定Java 基础而要进行Hadoop应用开发的人员阅读。
                                        </p>]<p><h2>内容简介</h2></p>[<p>1.版本新。本书采用Hadoop3，版本较新，帮助读者学习前沿技术。 2.项目大。深度剖析日志分析、推荐系统、垃圾消息三大企业级项目实战案例。读者稍加改造，即可在生产环境中使用。 3.内容全。详细介绍HDFS、MapReduce、HBase、Hive、Sqoop、Spark 等主流大数据工具。 4.资源多。赠送12小时视频讲解和全书配套范例源码。 5.在线答疑。本书提供答疑球球群，在线答疑。群号：243363382。 </p>]<p><h2>作者简介</h2></p>[<p>吴章勇，现任中软国际分公司技术总监，曾任阿里巴巴集团架构师，持有信息系统项目管理师高级证书；为培训公司策划大数据课程体系，主持开发过多个大数据项目，有15年以上开发和培训经验；录制过《Hadoop大数据技术》等经典在线教育视频课程。 杨强，现任中软国际项目总监，中软国际ETC CTO办公室高级技术顾问，移动增值数据服务项目经理，拥有10年大型软件项目开发及培训经验，对分布式及异构系统集成 有深入研究。参与主持多个大型项目并发表多篇重要论文。</p>]<p><h2>目录</h2></p>
    目 录**篇　Hadoop技术　1第1章　大数据与Hadoop概述　031.1　大数据概述　031.1.1　大数据的定义　031.1.2　大数据行业的发展　041.1.3　大数据的典型应用　041.2　Hadoop概述　061.2.1　Hadoop简介　061.2.2　Hadoop生态子项目　071.2.3　Hadoop 3.X的新特性　091.3　小结　091.4　配套视频　10第2章　Hadoop伪分布式安装　112.1　Hadoop伪分布式安装前的准备　112.1.1　安装VMware　112.1.2　安装CentOS 7　122.1.3　配置CentOS 7：接受协议　152.1.4　配置CentOS 7：登录系统　162.1.5　配置CentOS 7：设置IP　162.1.6　配置CentOS 7：修改主机名　172.1.7　配置CentOS 7：配置hosts文件　182.1.8　配置CentOS 7：关闭防火墙　182.1.9　配置CentOS 7：禁用selinux　192.1.10　配置CentOS 7：设置SSH免密码登录　192.1.11　配置CentOS 7：重启　202.2　Hadoop伪分布式安装　212.2.1　安装WinSCP　212.2.2　安装PieTTY　222.2.3　安装JDK　232.2.4　安装Hadoop　242.3　Hadoop验证　282.3.1　格式化　282.3.2　启动Hadoop　292.3.3　查看Hadoop相关进程　292.3.4　浏览文件　302.3.5　浏览器访问　302.4　小结　312.5　配套视频　31第3章　Hadoop分布式文件系统——HDFS　323.1　HDFS原理　323.1.1　HDFS的假设前提和设计目标　323.1.2　HDFS的组件　333.1.3　HDFS数据复制　363.1.4　HDFS健壮性　363.1.5　HDFS数据组织　383.2　HDFS Shell　393.2.1　Hadoop文件操作命令　393.2.2　Hadoop系统管理命令　443.3　HDFS Java API　463.3.1　搭建Linux下Eclipse开发环境　463.3.2　为Eclipse安装Hadoop插件　473.3.3　HDFS Java API示例　493.4　小结　563.5　配套视频　56第4章　分布式计算框架MapReduce　574.1　MapReduce原理　574.1.1　MapReduce概述　574.1.2　MapReduce的主要功能　594.1.3　MapReduce的处理流程　594.2　MapReduce编程基础　614.2.1　内置数据类型介绍　614.2.2　WordCount入门示例　634.2.3　MapReduce分区与自定义数据类型　674.3　MapReduce综合实例——数据去重　714.3.1　实例描述　714.3.2　设计思路　724.3.3　程序代码　734.3.4　运行结果　744.4　MapReduce综合实例——数据排序　754.4.1　实例描述　754.4.2　设计思路　764.4.3　程序代码　774.4.4　运行结果　794.5　MapReduce综合实例——求学生平均成绩　794.5.1　实例描述　794.5.2　设计思路　804.5.3　程序代码　814.5.4　运行结果　834.6　MapReduce综合实例——WordCount高级示例　844.7　小结　874.8　配套视频　87第二篇　Hadoop 生态系统的主要大数据工具整合应用　89第5章　NoSQL数据库HBase　915.1　HBase原理　915.1.1　HBase概述　915.1.2　HBase核心概念　925.1.3　HBase的关键流程　955.2　HBase伪分布式安装　975.2.1　安装HBase的前提条件　985.2.2　解压并配置环境变量　985.2.3　配置HBase参数　995.2.4　验证HBase　1005.3　HBase Shell　1035.3.1　HBase Shell常用命令　1035.3.2　HBase Shell综合示例　1095.3.3　HBase Shell的全部命令　1125.4　小结　1145.5　配套视频　114第6章　HBase高级特性　1156.1　HBase Java API　1156.1.1　HBase Java API介绍　1156.1.2　HBase Java API示例　1206.2　HBase与MapReduce的整合　1306.2.1　HBase与MapReduce的整合概述　1306.2.2　HBase与MapReduce的整合示例　1306.3　小结　1346.4　配套视频　134第7章　分布式数据仓库Hive　1357.1　Hive概述　1357.1.1　Hive的定义　1357.1.2　Hive的设计特征　1367.1.3　Hive的体系结构　1367.2　Hive伪分布式安装　1377.2.1　安装Hive的前提条件　1377.2.2　解压并配置环境变量　1387.2.3　安装MySQL　1397.2.4　配置Hive　1437.2.5　验证Hive　1457.3　Hive QL的基础功能　1467.3.1　操作数据库　1467.3.2　创建表　1477.3.3　数据准备　1507.4　Hive QL的高级功能　1537.4.1　select查询　1547.4.2　函数　1547.4.3　统计函数　1547.4.4　distinct去除重复值　1557.4.5　limit限制返回记录的条数　1567.4.6　为列名取别名　1567.4.7　case when then多路分支　1567.4.8　like模糊查询　1577.4.9　group by分组统计　1577.4.10　having过滤分组统计结果　1577.4.11　inner join内联接　1587.4.12　left outer join和right outer join外联接　1597.4.13　full outer join外部联接　1597.4.14　order by排序　1607.4.15　where查找　1607.5　小结　1617.6　配套视频　162第8章　Hive高级特性　1638.1　Beeline　1638.1.1　使用Beeline的前提条件　1638.1.2　Beeline的基本操作　1648.1.3　Beeline的参数选项与管理命令　1668.2　Hive JDBC　1678.2.1　运行Hive JDBC的前提条件　1678.2.2　Hive JDBC基础示例　1678.2.3　Hive JDBC综合示例　1698.3　Hive函数　1748.3.1　内置函数　1748.3.2　自定义函数　1758.4　Hive表的高级特性　1818.4.1　外部表　1818.4.2　分区表　1828.5　小结　1858.6　配套视频　185第9章　数据转换工具Sqoop　1869.1　Sqoop概述与安装　1869.1.1　Sqoop概述　1869.1.2　Sqoop安装　1879.2　Sqoop导入数据　1899.2.1　更改MySQL的root用户密码　1899.2.2　准备数据　1909.2.3　导入数据到HDFS　1919.2.4　查看HDFS数据　1929.2.5　导入数据到Hive　1939.2.6　查看Hive数据　1939.3　Sqoop导出数据　1949.3.1　准备MySQL表　1949.3.2　导出数据到MySQL　1949.3.3　查看MySQL中的导出数据　1959.4　深入理解Sqoop的导入与导出　1969.5　小结　2039.6　配套视频　203第10章　内存计算框架Spark　20410.1　Spark入门　20410.1.1　Spark概述　20410.1.2　Spark伪分布式安装　20510.1.3　由Java到Scala　20910.1.4　Spark的应用　21210.1.5　Spark入门示例　21710.2　Spark Streaming　22010.2.1　Spark Streaming概述　22010.2.2　Spark Streaming示例　22110.3　Spark SQL　22410.3.1　Spark SQL概述　22410.3.2　spark-sql命令　22510.3.3　使用Scala操作Spark SQL　22710.4　小结　22810.5　配套视频　229第11章　Hadoop及其常用组件集群安装　23011.1　Hadoop集群安装　23011.1.1　安装并配置CentOS　23011.1.2　安装JDK　23611.1.3　安装Hadoop　23711.1.4　远程复制文件　24111.1.5　验证Hadoop　24211.2　HBase集群安装　24411.2.1　解压并配置环境变量　24411.2.2　配置HBase参数　24511.2.3　远程复制文件　24611.2.4　验证HBase　24711.3　Hive集群安装　24911.3.1　解压并配置环境变量　24911.3.2　安装MySQL　25011.3.3　配置Hive　25211.3.4　验证Hive　25411.4　Spark集群安装　25411.4.1　安装Scala　25411.4.2　安装Spark　25411.4.3　配置Spark　25511.4.4　远程复制文件　25611.4.5　验证Spark　25711.5　小结　25911.6　配套视频　259第三篇　实战篇　261第12章　海量Web日志分析系统　26312.1　案例介绍　26312.1.1　分析Web日志数据的目的　26312.1.2　Web日志分析的典型应用场景　26512.1.3　日志的不确定性　26512.2　案例分析　26612.2.1　日志分析的KPI　26712.2.2　案例系统结构　26712.2.3　日志分析方法　26812.3　案例实现　27312.3.1　定义日志相关属性字段　27312.3.2　数据合法标识（在分析时是否被过滤）　27412.3.3　解析日志　27412.3.4　日志合法性过滤　27512.3.5　页面访问量统计的实现　27612.3.6　页面独立IP访问量统计的实现　27812.3.7　用户单位时间PV的统计实现　28012.3.8　用户访问设备信息统计的实现　28212.4　小结　28312.5　配套视频　283第13章　电商商品推荐系统　28413.1　案例介绍　28413.1.1　推荐算法　28413.1.2　案例的意义　28513.1.3　案例需求　28513.2　案例设计　28613.2.1　协同过滤　28613.2.2　基于用户的协同过滤算法　28913.2.3　基于物品的协同过滤算法　29213.2.4　算法实现设计　29513.2.5　推荐步骤与架构设计　29813.3　案例实现　29813.3.1　实现HDFS文件操作工具　29913.3.2　实现任务步骤1：汇总用户对所有物品的评分信息　30213.3.3　实现任务步骤2：获取物品同现矩阵　30513.3.4　实现任务步骤3：合并同现矩阵和评分矩阵　30713.3.5　实现任务步骤4：计算推荐结果　31013.3.6　实现统一的任务调度　31613.4　小结　31713.5　配套视频　317第14章　分布式垃圾消息识别系统　31814.1　案例介绍　31814.1.1　案例内容　31814.1.2　案例应用的主体结构　31914.1.3　案例运行结果　32114.2　RPC远程方法调用的设计　32214.2.1　Java EE的核心优势：RMI　32214.2.2　RMI的基本原理　32414.2.3　自定义RPC组件分析　32514.3　数据分析设计　32814.3.1　垃圾消息识别算法——朴素贝叶斯算法　32814.3.2　进行分布式贝叶斯分类学习时的全局计数器　33014.3.3　数据清洗分析结果存储　33214.4　案例实现　33314.4.1　自定义的RPC组件服务端相关实现　33314.4.2　自定义的RPC组件客户端相关实现　34214.4.3　业务服务器实现　34714.4.4　业务客户端实现　36714.5　小结　37014.6　配套视频　370
